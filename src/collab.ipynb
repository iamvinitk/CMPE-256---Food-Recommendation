{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas dataframe\n",
    "data = pd.read_csv(\"../dataset/interactions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  recipe_id  rating\n",
      "0     2046       4684     5.0\n",
      "1     2046        517     5.0\n",
      "2     1773       7435     5.0\n",
      "3     1773        278     4.0\n",
      "4     2046       3431     5.0\n"
     ]
    }
   ],
   "source": [
    "data = data[[\"user_id\", \"recipe_id\", \"rating\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841895</td>\n",
       "      <td>268243</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29782</td>\n",
       "      <td>10198</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27060</td>\n",
       "      <td>155186</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>881750</td>\n",
       "      <td>79469</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>456641</td>\n",
       "      <td>148018</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>222433</td>\n",
       "      <td>64138</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>425154</td>\n",
       "      <td>21882</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>481092</td>\n",
       "      <td>405481</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>329138</td>\n",
       "      <td>136589</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63128</td>\n",
       "      <td>39902</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(data, bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = collab_learner(dls,use_nn=True, n_factors=16, y_range=(0, 5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.00% [3/5 30:07&lt;20:05]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.892431</td>\n",
       "      <td>0.848385</td>\n",
       "      <td>10:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.835186</td>\n",
       "      <td>0.845575</td>\n",
       "      <td>09:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.862547</td>\n",
       "      <td>0.838719</td>\n",
       "      <td>09:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='398' class='' max='8736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.56% [398/8736 00:27&lt;09:27 0.8253]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2046</td>\n",
       "      <td>4684</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2046</td>\n",
       "      <td>517</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1773</td>\n",
       "      <td>7435</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773</td>\n",
       "      <td>278</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2046</td>\n",
       "      <td>3431</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id  rating\n",
       "0     2046       4684     5.0\n",
       "1     2046        517     5.0\n",
       "2     1773       7435     5.0\n",
       "3     1773        278     4.0\n",
       "4     2046       3431     5.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.001).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    497938\n",
       "1    309630\n",
       "2     58439\n",
       "3     66847\n",
       "4    415204\n",
       "Name: user_id, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.user_id.head().map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 23:01:53.242697: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.string_lookup.StringLookup at 0x2f96e5be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(data[\"user_id\"].map(str))\n",
    "user_ids_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "recipe_ids_vocabulary.adapt(data[\"recipe_id\"].map(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.Model):\n",
    "    # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "    # these are still plain Keras Models.\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_model: tf.keras.Model,\n",
    "        recipe_model: tf.keras.Model,\n",
    "        task: tfrs.tasks.Retrieval):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set up user and movie representations.\n",
    "        self.user_model = user_model\n",
    "        self.recipe_model = recipe_model\n",
    "\n",
    "        # Set up a retrieval task.\n",
    "        self.task = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # Define how the loss is computed.\n",
    "\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        recipe_embeddings = self.recipe_model(features[\"recipe_id\"])\n",
    "        print(user_embeddings.shape)\n",
    "\n",
    "        return self.task(user_embeddings, recipe_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(1,), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data = tf.data.Dataset.from_tensor_slices(data.recipe_id.values.reshape(-1, 1))\n",
    "tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec={'user_id': TensorSpec(shape=(), dtype=tf.int64, name=None), 'recipe_id': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = tf.data.Dataset.from_tensor_slices(dict(data[['user_id', 'recipe_id']]))\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user and movie models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "recipe_model = tf.keras.Sequential([\n",
    "    recipe_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(recipe_ids_vocabulary.vocabulary_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    tf_data.batch(8).map(recipe_model)\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec={'user_id': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'recipe_id': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.uniform((128, 64))\n",
    "b = tf.random.uniform((128, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'retrieval_8' (type Retrieval).\n\n{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] ndims must be >= 2: 1 [Op:BatchMatMulV2]\n\nCall arguments received by layer 'retrieval_8' (type Retrieval):\n  • query_embeddings=tf.Tensor(shape=(8,), dtype=float32)\n  • candidate_embeddings=tf.Tensor(shape=(8, 1, 64), dtype=float32)\n  • sample_weight=None\n  • candidate_sampling_probability=None\n  • candidate_ids=None\n  • compute_metrics=True\n  • compute_batch_metrics=True",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m a \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform((\u001B[38;5;241m8\u001B[39m,))\n\u001B[1;32m     19\u001B[0m b \u001B[38;5;241m=\u001B[39m recipe_model(tf\u001B[38;5;241m.\u001B[39mconstant([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m8\u001B[39m]))\n\u001B[0;32m---> 20\u001B[0m \u001B[43mtask\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/tasks/retrieval.py:160\u001B[0m, in \u001B[0;36mRetrieval.call\u001B[0;34m(self, query_embeddings, candidate_embeddings, sample_weight, candidate_sampling_probability, candidate_ids, compute_metrics, compute_batch_metrics)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    120\u001B[0m          query_embeddings: tf\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m    121\u001B[0m          candidate_embeddings: tf\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    125\u001B[0m          compute_metrics: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    126\u001B[0m          compute_batch_metrics: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m tf\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m    127\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Computes the task loss and metrics.\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \n\u001B[1;32m    129\u001B[0m \u001B[38;5;124;03m  The main argument are pairs of query and candidate embeddings: the first row\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;124;03m    loss: Tensor of loss values.\u001B[39;00m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 160\u001B[0m   scores \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m      \u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcandidate_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranspose_b\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m   num_queries \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mshape(scores)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    164\u001B[0m   num_candidates \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mshape(scores)[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Exception encountered when calling layer 'retrieval_8' (type Retrieval).\n\n{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] ndims must be >= 2: 1 [Op:BatchMatMulV2]\n\nCall arguments received by layer 'retrieval_8' (type Retrieval):\n  • query_embeddings=tf.Tensor(shape=(8,), dtype=float32)\n  • candidate_embeddings=tf.Tensor(shape=(8, 1, 64), dtype=float32)\n  • sample_weight=None\n  • candidate_sampling_probability=None\n  • candidate_ids=None\n  • compute_metrics=True\n  • compute_batch_metrics=True"
     ]
    }
   ],
   "source": [
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    tf_data.batch(8).map(recipe_model)\n",
    "  )\n",
    ")\n",
    "\n",
    "# Create a dummy dataset\n",
    "tf_data = tf.data.Dataset.from_tensor_slices({\n",
    "    \"recipe_id\": tf.constant([1, 2, 3, 4, 5, 6, 7, 8]),\n",
    "    \"recipe_features\": tf.random.uniform((8, 64))\n",
    "})\n",
    "\n",
    "# Define the recipe model\n",
    "recipe_input = tf.keras.Input(shape=(1,), dtype=tf.int32)\n",
    "recipe_embedding = tf.keras.layers.Embedding(input_dim=10, output_dim=64)(recipe_input)\n",
    "recipe_model = tf.keras.Model(inputs=recipe_input, outputs=recipe_embedding)\n",
    "\n",
    "# Call the task on a batch of inputs\n",
    "a = tf.random.uniform((8,))\n",
    "b = recipe_model(tf.constant([1, 2, 3, 4, 5, 6, 7, 8]))\n",
    "task(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'streaming_7' (type Streaming).\n\nin user code:\n\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\", line 429, in top_scores  *\n        scores, indices = tf.math.top_k(scores, k=k_, sorted=self._sorted)\n\n    ValueError: input must have last dimension >= k = 100 but is 1 for '{{node TopKV2}} = TopKV2[T=DT_FLOAT, sorted=true](MatMul, Minimum)' with input shapes: [?,128,1], [] and with computed input tensors: input[1] = <100>.\n\n\nCall arguments received by layer 'streaming_7' (type Streaming):\n  • queries=tf.Tensor(shape=(128, 64), dtype=float32)\n  • k=100",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtask\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/tasks/retrieval.py:198\u001B[0m, in \u001B[0;36mRetrieval.call\u001B[0;34m(self, query_embeddings, candidate_embeddings, sample_weight, candidate_sampling_probability, candidate_ids, compute_metrics, compute_batch_metrics)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compute_metrics:\n\u001B[1;32m    196\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m metric \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_factorized_metrics:\n\u001B[1;32m    197\u001B[0m     update_ops\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 198\u001B[0m         \u001B[43mmetric\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_state\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m            \u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# Slice to the size of query embeddings\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# if `candidate_embeddings` contains extra negatives.\u001B[39;49;00m\n\u001B[1;32m    202\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcandidate_embeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrue_candidate_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcandidate_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m     )\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compute_batch_metrics:\n\u001B[1;32m    207\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m metric \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_metrics:\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py:136\u001B[0m, in \u001B[0;36mFactorizedTopK.update_state\u001B[0;34m(self, query_embeddings, true_candidate_embeddings, true_candidate_ids, sample_weight)\u001B[0m\n\u001B[1;32m    126\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    127\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe candidate generation layer (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_candidates\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) does not return \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    128\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexact results. To perform evaluation using that layer, you must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    129\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msupply `true_candidate_ids`, which will be checked against \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    130\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe candidate ids returned from the candidate generation layer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    131\u001B[0m   )\n\u001B[1;32m    133\u001B[0m positive_scores \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_sum(\n\u001B[1;32m    134\u001B[0m     query_embeddings \u001B[38;5;241m*\u001B[39m true_candidate_embeddings, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 136\u001B[0m top_k_predictions, retrieved_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m update_ops \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m true_candidate_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    142\u001B[0m   \u001B[38;5;66;03m# We're using ID-based evaluation.\u001B[39;00m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/layers/factorized_top_k.py:488\u001B[0m, in \u001B[0;36mStreaming.call\u001B[0;34m(self, queries, k)\u001B[0m\n\u001B[1;32m    483\u001B[0m initial_state \u001B[38;5;241m=\u001B[39m (tf\u001B[38;5;241m.\u001B[39mzeros((tf\u001B[38;5;241m.\u001B[39mshape(queries)[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m0\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32),\n\u001B[1;32m    484\u001B[0m                  tf\u001B[38;5;241m.\u001B[39mzeros((tf\u001B[38;5;241m.\u001B[39mshape(queries)[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m0\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mindex_dtype))\n\u001B[1;32m    486\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _wrap_batch_too_small_error(k):\n\u001B[1;32m    487\u001B[0m   results \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 488\u001B[0m       candidates\n\u001B[1;32m    489\u001B[0m       \u001B[38;5;66;03m# Compute scores over all candidates, and select top k in each batch.\u001B[39;00m\n\u001B[1;32m    490\u001B[0m       \u001B[38;5;66;03m# Each element is a ([query_batch_size, k] tensor,\u001B[39;00m\n\u001B[1;32m    491\u001B[0m       \u001B[38;5;66;03m# [query_batch_size, k] tensor) of scores and indices (where query_\u001B[39;00m\n\u001B[1;32m    492\u001B[0m       \u001B[38;5;66;03m# batch_size is the leading dimension of the input query embeddings).\u001B[39;00m\n\u001B[1;32m    493\u001B[0m       \u001B[38;5;241m.\u001B[39mmap(top_scores, num_parallel_calls\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_parallel_calls)\n\u001B[1;32m    494\u001B[0m       \u001B[38;5;66;03m# Reduce into a single tuple of output tensors by keeping a running\u001B[39;00m\n\u001B[1;32m    495\u001B[0m       \u001B[38;5;66;03m# tally of top k scores and indices.\u001B[39;00m\n\u001B[1;32m    496\u001B[0m       \u001B[38;5;241m.\u001B[39mreduce(initial_state, top_k))\n\u001B[1;32m    498\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_file4nj4bo7y.py:32\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__top_scores\u001B[0;34m(candidate_index, candidate_batch)\u001B[0m\n\u001B[1;32m     30\u001B[0m k_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk_\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     31\u001B[0m ag__\u001B[38;5;241m.\u001B[39mif_stmt(ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m_handle_incomplete_batches, if_body, else_body, get_state, set_state, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk_\u001B[39m\u001B[38;5;124m'\u001B[39m,), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 32\u001B[0m (scores, indices) \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mtop_k, (ag__\u001B[38;5;241m.\u001B[39mld(scores),), \u001B[38;5;28mdict\u001B[39m(k\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(k_), \u001B[38;5;28msorted\u001B[39m\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m_sorted), fscope)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     34\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer 'streaming_7' (type Streaming).\n\nin user code:\n\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\", line 429, in top_scores  *\n        scores, indices = tf.math.top_k(scores, k=k_, sorted=self._sorted)\n\n    ValueError: input must have last dimension >= k = 100 but is 1 for '{{node TopKV2}} = TopKV2[T=DT_FLOAT, sorted=true](MatMul, Minimum)' with input shapes: [?,128,1], [] and with computed input tensors: input[1] = <100>.\n\n\nCall arguments received by layer 'streaming_7' (type Streaming):\n  • queries=tf.Tensor(shape=(128, 64), dtype=float32)\n  • k=100"
     ]
    }
   ],
   "source": [
    "task(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "(None, 64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/ipykernel_4601/3312599068.py\", line 26, in compute_loss\n        return self.task(user_embeddings, recipe_embeddings)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py\", line 159, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py\", line 155, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py\", line 154, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filed33q43k2.py\", line 50, in tf__update_state\n        (top_k_predictions, retrieved_ids) = ag__.converted_call(ag__.ld(self)._candidates, (ag__.ld(query_embeddings),), dict(k=ag__.converted_call(ag__.ld(max), (ag__.ld(self)._ks,), None, fscope)), fscope)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 163, in tf__call\n        results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 98, in top_k\n        joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n\n    ValueError: Exception encountered when calling layer 'retrieval_6' (type Retrieval).\n    \n    in user code:\n    \n        File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py\", line 136, in update_state  *\n            top_k_predictions, retrieved_ids = self._candidates(\n        File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 163, in tf__call\n            results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n        File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 98, in top_k\n            joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n    \n        ValueError: Exception encountered when calling layer 'streaming_6' (type Streaming).\n        \n        in user code:\n        \n            File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\", line 454, in top_k  *\n                joined_scores = tf.concat([state_scores, x_scores], axis=1)\n        \n            ValueError: Shape must be rank 2 but is rank 3 for '{{node concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](args_0, args_2, concat/axis)' with input shapes: [?,0], [?,?,?], [].\n        \n        \n        Call arguments received by layer 'streaming_6' (type Streaming):\n          • queries=tf.Tensor(shape=(None, 64), dtype=float32)\n          • k=100\n    \n    \n    Call arguments received by layer 'retrieval_6' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdagrad(\u001B[38;5;241m0.5\u001B[39m))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Train for 3 epochs.\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mratings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4096\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_fileyijd7vu4.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py:68\u001B[0m, in \u001B[0;36mModel.train_step\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m---> 68\u001B[0m   loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(inputs, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     70\u001B[0m   \u001B[38;5;66;03m# Handle regularization losses as well.\u001B[39;00m\n\u001B[1;32m     71\u001B[0m   regularization_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosses)\n",
      "Cell \u001B[0;32mIn[42], line 26\u001B[0m, in \u001B[0;36mMovieLensModel.compute_loss\u001B[0;34m(self, features, training)\u001B[0m\n\u001B[1;32m     23\u001B[0m recipe_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecipe_model(features[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecipe_id\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(user_embeddings\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecipe_embeddings\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py:159\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001B[0;34m(self, query_embeddings, candidate_embeddings, sample_weight, candidate_sampling_probability, candidate_ids, compute_metrics, compute_batch_metrics)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21melse_body_5\u001B[39m():\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m--> 159\u001B[0m ag__\u001B[38;5;241m.\u001B[39mif_stmt(ag__\u001B[38;5;241m.\u001B[39mld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state_9\u001B[39m():\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ()\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py:155\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5\u001B[0;34m()\u001B[0m\n\u001B[1;32m    153\u001B[0m     metric \u001B[38;5;241m=\u001B[39m itr_1\n\u001B[1;32m    154\u001B[0m     ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(update_ops)\u001B[38;5;241m.\u001B[39mappend, (ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(metric)\u001B[38;5;241m.\u001B[39mupdate_state, (ag__\u001B[38;5;241m.\u001B[39mld(query_embeddings), ag__\u001B[38;5;241m.\u001B[39mld(candidate_embeddings)[:ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mshape, (ag__\u001B[38;5;241m.\u001B[39mld(query_embeddings),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)[\u001B[38;5;241m0\u001B[39m]]), \u001B[38;5;28mdict\u001B[39m(true_candidate_ids\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(candidate_ids)), fscope),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m--> 155\u001B[0m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfor_stmt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_factorized_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloop_body_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_state_6\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_state_6\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43miterate_names\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmetric\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py:154\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5.<locals>.loop_body_1\u001B[0;34m(itr_1)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloop_body_1\u001B[39m(itr_1):\n\u001B[1;32m    153\u001B[0m     metric \u001B[38;5;241m=\u001B[39m itr_1\n\u001B[0;32m--> 154\u001B[0m     ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(update_ops)\u001B[38;5;241m.\u001B[39mappend, (\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcandidate_embeddings\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embeddings\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrue_candidate_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcandidate_ids\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m,), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filed33q43k2.py:50\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state\u001B[0;34m(self, query_embeddings, true_candidate_embeddings, true_candidate_ids, sample_weight)\u001B[0m\n\u001B[1;32m     48\u001B[0m ag__\u001B[38;5;241m.\u001B[39mif_stmt(ag__\u001B[38;5;241m.\u001B[39mand_(\u001B[38;5;28;01mlambda\u001B[39;00m : ag__\u001B[38;5;241m.\u001B[39mld(true_candidate_ids) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mlambda\u001B[39;00m : ag__\u001B[38;5;241m.\u001B[39mnot_(ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m_candidates\u001B[38;5;241m.\u001B[39mis_exact, (), \u001B[38;5;28;01mNone\u001B[39;00m, fscope))), if_body, else_body, get_state, set_state, (), \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     49\u001B[0m positive_scores \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mreduce_sum, (ag__\u001B[38;5;241m.\u001B[39mld(query_embeddings) \u001B[38;5;241m*\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(true_candidate_embeddings),), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), fscope)\n\u001B[0;32m---> 50\u001B[0m (top_k_predictions, retrieved_ids) \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m_candidates, (ag__\u001B[38;5;241m.\u001B[39mld(query_embeddings),), \u001B[38;5;28mdict\u001B[39m(k\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mmax\u001B[39m), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m_ks,), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)), fscope)\n\u001B[1;32m     51\u001B[0m update_ops \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state_4\u001B[39m():\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py:163\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001B[0;34m(self, queries, k)\u001B[0m\n\u001B[1;32m    161\u001B[0m initial_state \u001B[38;5;241m=\u001B[39m (ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mzeros, ((ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mshape, (ag__\u001B[38;5;241m.\u001B[39mld(queries),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m0\u001B[39m),), \u001B[38;5;28mdict\u001B[39m(dtype\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mfloat32), fscope), ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mzeros, ((ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mshape, (ag__\u001B[38;5;241m.\u001B[39mld(queries),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m0\u001B[39m),), \u001B[38;5;28mdict\u001B[39m(dtype\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(index_dtype)), fscope))\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ag__\u001B[38;5;241m.\u001B[39mld(_wrap_batch_too_small_error)(ag__\u001B[38;5;241m.\u001B[39mld(k)):\n\u001B[0;32m--> 163\u001B[0m     results \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(candidates)\u001B[38;5;241m.\u001B[39mmap, (ag__\u001B[38;5;241m.\u001B[39mld(top_scores),), \u001B[38;5;28mdict\u001B[39m(num_parallel_calls\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m_num_parallel_calls), fscope)\u001B[38;5;241m.\u001B[39mreduce, (ag__\u001B[38;5;241m.\u001B[39mld(initial_state), ag__\u001B[38;5;241m.\u001B[39mld(top_k)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py:98\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.top_k\u001B[0;34m(state, x)\u001B[0m\n\u001B[1;32m     96\u001B[0m (state_scores, state_indices) \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(state)\n\u001B[1;32m     97\u001B[0m (x_scores, x_indices) \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(x)\n\u001B[0;32m---> 98\u001B[0m joined_scores \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mconcat, ([ag__\u001B[38;5;241m.\u001B[39mld(state_scores), ag__\u001B[38;5;241m.\u001B[39mld(x_scores)],), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), fscope_2)\n\u001B[1;32m     99\u001B[0m joined_indices \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mconcat, ([ag__\u001B[38;5;241m.\u001B[39mld(state_indices), ag__\u001B[38;5;241m.\u001B[39mld(x_indices)],), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), fscope_2)\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state_3\u001B[39m():\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/ipykernel_4601/3312599068.py\", line 26, in compute_loss\n        return self.task(user_embeddings, recipe_embeddings)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py\", line 159, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py\", line 155, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filef4og8yws.py\", line 154, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filed33q43k2.py\", line 50, in tf__update_state\n        (top_k_predictions, retrieved_ids) = ag__.converted_call(ag__.ld(self)._candidates, (ag__.ld(query_embeddings),), dict(k=ag__.converted_call(ag__.ld(max), (ag__.ld(self)._ks,), None, fscope)), fscope)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 163, in tf__call\n        results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 98, in top_k\n        joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n\n    ValueError: Exception encountered when calling layer 'retrieval_6' (type Retrieval).\n    \n    in user code:\n    \n        File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/tasks/retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py\", line 136, in update_state  *\n            top_k_predictions, retrieved_ids = self._candidates(\n        File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 163, in tf__call\n            results = ag__.converted_call(ag__.converted_call(ag__.ld(candidates).map, (ag__.ld(top_scores),), dict(num_parallel_calls=ag__.ld(self)._num_parallel_calls), fscope).reduce, (ag__.ld(initial_state), ag__.ld(top_k)), None, fscope)\n        File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_filel32itaww.py\", line 98, in top_k\n            joined_scores = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(state_scores), ag__.ld(x_scores)],), dict(axis=1), fscope_2)\n    \n        ValueError: Exception encountered when calling layer 'streaming_6' (type Streaming).\n        \n        in user code:\n        \n            File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\", line 454, in top_k  *\n                joined_scores = tf.concat([state_scores, x_scores], axis=1)\n        \n            ValueError: Shape must be rank 2 but is rank 3 for '{{node concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](args_0, args_2, concat/axis)' with input shapes: [?,0], [?,?,?], [].\n        \n        \n        Call arguments received by layer 'streaming_6' (type Streaming):\n          • queries=tf.Tensor(shape=(None, 64), dtype=float32)\n          • k=100\n    \n    \n    Call arguments received by layer 'retrieval_6' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, 64), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(user_model, recipe_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ratings.batch(4096), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MovielensModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create a retrieval model.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mMovielensModel\u001B[49m(user_model, recipe_model, task)\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdagrad(\u001B[38;5;241m0.5\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'MovielensModel' is not defined"
     ]
    }
   ],
   "source": [
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    movies.batch(100).map(lambda title: (title, model.movie_model(title))))\n",
    "\n",
    "# Get some recommendations.\n",
    "_, titles = index(np.array([\"42\"]))\n",
    "print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train.\n",
    "model.fit(ratings.batch(4096), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up retrieval using trained representations.\n",
    "index = tfrs.layers.ann.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    movies.batch(100).map(lambda title: (title, model.movie_model(title)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(np.array([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/ipykernel_4601/1317723946.py\", line 49, in compute_loss\n        ratings = features.pop(\"rating\")\n\n    AttributeError: 'tuple' object has no attribute 'pop'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[62], line 67\u001B[0m\n\u001B[1;32m     61\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices(({\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: user_ids,\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecipe_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: recipe_ids\n\u001B[1;32m     64\u001B[0m }, rating))\n\u001B[1;32m     66\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 67\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mratings_df\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/__autograph_generated_fileyijd7vu4.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py:68\u001B[0m, in \u001B[0;36mModel.train_step\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[0;32m---> 68\u001B[0m   loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(inputs, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     70\u001B[0m   \u001B[38;5;66;03m# Handle regularization losses as well.\u001B[39;00m\n\u001B[1;32m     71\u001B[0m   regularization_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosses)\n",
      "Cell \u001B[0;32mIn[62], line 49\u001B[0m, in \u001B[0;36mRecommenderModel.compute_loss\u001B[0;34m(self, features, training)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_loss\u001B[39m(\u001B[38;5;28mself\u001B[39m, features, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m---> 49\u001B[0m   ratings \u001B[38;5;241m=\u001B[39m \u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrating\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     50\u001B[0m   rating_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(features)\n\u001B[1;32m     51\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask(\n\u001B[1;32m     52\u001B[0m       labels\u001B[38;5;241m=\u001B[39mratings,\n\u001B[1;32m     53\u001B[0m       predictions\u001B[38;5;241m=\u001B[39mrating_predictions,\n\u001B[1;32m     54\u001B[0m   )\n",
      "\u001B[0;31mAttributeError\u001B[0m: in user code:\n\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/vinitkanani/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/3z/s0qdvzzd2kgc2kdxkfvxy9ym0000gn/T/ipykernel_4601/1317723946.py\", line 49, in compute_loss\n        ratings = features.pop(\"rating\")\n\n    AttributeError: 'tuple' object has no attribute 'pop'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.DataFrame({\n",
    "    \"user_id\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"recipe_id\": [26059, 58970, 27457, 7492, 26820, 37902, 23321, 979, 43133, 29019],\n",
    "    \"rating\": [3, 5, 4, 5, 5, 3, 5, 5, 5, 4]\n",
    "})\n",
    "\n",
    "# Create user and recipe feature layers\n",
    "user_ids = ratings_df[\"user_id\"]\n",
    "recipe_ids = ratings_df[\"recipe_id\"]\n",
    "rating = ratings_df[\"rating\"]\n",
    "user_embedding = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=user_ids.astype(str), mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(user_ids) + 1, 32)\n",
    "])\n",
    "recipe_embedding = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=recipe_ids.astype(str), mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(recipe_ids) + 1, 32)\n",
    "])\n",
    "\n",
    "# Define the model\n",
    "class RecommenderModel(tfrs.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.user_embedding = user_embedding\n",
    "    self.recipe_embedding = recipe_embedding\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features):\n",
    "    user_embedding = self.user_embedding(features[\"user_id\"])\n",
    "    recipe_embedding = self.recipe_embedding(features[\"recipe_id\"])\n",
    "    return self.rating_model(tf.concat([user_embedding, recipe_embedding], axis=1))\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    ratings = features.pop(\"rating\")\n",
    "    rating_predictions = self(features)\n",
    "    return self.task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "\n",
    "# Instantiate the model and compile it\n",
    "model = RecommenderModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Prepare the input data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    \"user_id\": user_ids,\n",
    "    \"recipe_id\": recipe_ids\n",
    "}, rating))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset.shuffle(len(ratings_df)).batch(2), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing data for input \"input_1\". You passed a data dictionary with keys ['index', 'user_id', 'recipe_id']. Expected the following keys: ['input_1']",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 21\u001B[0m\n\u001B[1;32m     16\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m create_dataset(data[train_size:])\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Define the retrieval task\u001B[39;00m\n\u001B[1;32m     19\u001B[0m task \u001B[38;5;241m=\u001B[39m tfrs\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mRetrieval(\n\u001B[1;32m     20\u001B[0m     metrics\u001B[38;5;241m=\u001B[39mtfrs\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mFactorizedTopK(\n\u001B[0;32m---> 21\u001B[0m         candidates\u001B[38;5;241m=\u001B[39m\u001B[43mtest_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecipe_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     )\n\u001B[1;32m     23\u001B[0m )\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Define the model\u001B[39;00m\n\u001B[1;32m     26\u001B[0m user_model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mSequential([\n\u001B[1;32m     27\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mStringLookup(\n\u001B[1;32m     28\u001B[0m         vocabulary\u001B[38;5;241m=\u001B[39muser_ids, mask_token\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     29\u001B[0m     ),\n\u001B[1;32m     30\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mEmbedding(\u001B[38;5;28mlen\u001B[39m(user_ids) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, embedding_dimension)\n\u001B[1;32m     31\u001B[0m ])\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[1;32m   2236\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001B[39;00m\n\u001B[1;32m   2237\u001B[0m \u001B[38;5;66;03m# dataset_ops).\u001B[39;00m\n\u001B[1;32m   2238\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[1;32m   2239\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m map_op\n\u001B[0;32m-> 2240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_v2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2241\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2243\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2245\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:37\u001B[0m, in \u001B[0;36m_map_v2\u001B[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[1;32m     34\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m debug_mode\u001B[38;5;241m.\u001B[39mDEBUG_MODE:\n\u001B[1;32m     35\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `deterministic` argument has no effect unless the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     36\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`num_parallel_calls` argument is specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 37\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MapDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     40\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _ParallelMapDataset(\n\u001B[1;32m     41\u001B[0m       input_dataset,\n\u001B[1;32m     42\u001B[0m       map_func,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m       preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     46\u001B[0m       name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:107\u001B[0m, in \u001B[0;36m_MapDataset.__init__\u001B[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism \u001B[38;5;241m=\u001B[39m use_inter_op_parallelism\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preserve_cardinality \u001B[38;5;241m=\u001B[39m preserve_cardinality\n\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mstructured_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_legacy_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m name\n\u001B[1;32m    113\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m gen_dataset_ops\u001B[38;5;241m.\u001B[39mmap_dataset(\n\u001B[1;32m    114\u001B[0m     input_dataset\u001B[38;5;241m.\u001B[39m_variant_tensor,  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    118\u001B[0m     preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preserve_cardinality,\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_common_args)\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[1;32m    254\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    255\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    256\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    257\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    258\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    259\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[0;32m--> 261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[1;32m    263\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001B[0m, in \u001B[0;36mTracingCompiler.get_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    224\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[1;32m    225\u001B[0m \n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;124;03m      `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 232\u001B[0m   concrete_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    234\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    235\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001B[0m, in \u001B[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_spec\u001B[38;5;241m.\u001B[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m--> 202\u001B[0m   concrete_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_concrete_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    203\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m    204\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_arg_keywords \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_concrete_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m    163\u001B[0m   args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_signature\n\u001B[1;32m    164\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m    393\u001B[0m   args \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39margs\n\u001B[1;32m    394\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39mkwargs\n\u001B[0;32m--> 396\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001B[39;00m\n\u001B[1;32m    400\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m concrete_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39m_function_captures  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001B[0m, in \u001B[0;36mTracingCompiler._create_concrete_function\u001B[0;34m(self, args, kwargs, func_graph)\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    297\u001B[0m   arg_names \u001B[38;5;241m=\u001B[39m base_arg_names\n\u001B[1;32m    299\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m monomorphic_function\u001B[38;5;241m.\u001B[39mConcreteFunction(\n\u001B[0;32m--> 300\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[1;32m    313\u001B[0m     spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[1;32m    315\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[1;32m    318\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1214\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001B[0m\n\u001B[1;32m   1211\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1212\u001B[0m   _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[0;32m-> 1214\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[1;32m   1217\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[1;32m   1218\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:238\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;129m@eager_function\u001B[39m\u001B[38;5;241m.\u001B[39mdefun_with_attributes(\n\u001B[1;32m    233\u001B[0m     input_signature\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_specs(\n\u001B[1;32m    234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_structure),\n\u001B[1;32m    235\u001B[0m     autograph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    236\u001B[0m     attributes\u001B[38;5;241m=\u001B[39mdefun_kwargs)\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[0;32m--> 238\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    239\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[1;32m    240\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:169\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[1;32m    168\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[0;32m--> 169\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m ret \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(ret)\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    691\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[0;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    455\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 458\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/git/personal/kaggle/kaggle/food-recommendation-venv/lib/python3.9/site-packages/keras/engine/input_spec.py:197\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[0;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m names:\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m inputs:\n\u001B[0;32m--> 197\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    198\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing data for input \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    199\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou passed a data dictionary with keys \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    200\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(inputs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    201\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected the following keys: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnames\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    202\u001B[0m         )\n\u001B[1;32m    203\u001B[0m     list_inputs\u001B[38;5;241m.\u001B[39mappend(inputs[name])\n\u001B[1;32m    204\u001B[0m inputs \u001B[38;5;241m=\u001B[39m list_inputs\n",
      "\u001B[0;31mValueError\u001B[0m: Missing data for input \"input_1\". You passed a data dictionary with keys ['index', 'user_id', 'recipe_id']. Expected the following keys: ['input_1']"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "\n",
    "# Convert data to tf.data.Dataset\n",
    "def create_dataset(dataframe):\n",
    "    ratings = dataframe.pop(\"rating\")\n",
    "    feature_ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(ratings)\n",
    "    return tf.data.Dataset.zip((feature_ds, label_ds))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_dataset = create_dataset(data[:train_size])\n",
    "test_dataset = create_dataset(data[train_size:])\n",
    "\n",
    "# Define the retrieval task\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=test_dataset.batch(100).map(recipe_model)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=user_ids, mask_token=None\n",
    "    ),\n",
    "    tf.keras.layers.Embedding(len(user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "recipe_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=recipe_ids, mask_token=None\n",
    "    ),\n",
    "    tf.keras.layers.Embedding(len(recipe_ids) + 1, embedding_dimension)\n",
    "])\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=test_dataset.batch(100).map(recipe_model)\n",
    ")\n",
    "model = RecommenderModel(user_model, recipe_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset.batch(4096), epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_dataset.batch(4096), return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
